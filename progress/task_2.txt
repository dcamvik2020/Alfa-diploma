Задание (до 21.10.22):
1) разобраться с метриками для аплифта
2) на каггл посмотреть соревнование на аплифт:
	прочитать стаатью по данным (просто полезно)
	посмотреть базовое решение и запустить его с данными
	попробовать улучшить базовое решение



Задание (до конца ноября):
1) попробовать написать свое решение
2) прослушать МО-2 от Соколова



Что сделал (кратко, ниже подробнее)
1) 
2) 
3) 
4) 
5) 
6) 


Последовательность вопросов/проблем/удивлений:
1) (удивление) 13 млн строк в данных, базовое решение (hist grad boost) не дало ни одного FP, TP, но дала почти 100% TN
	мысли:  в самом начале даже ноутбука было сказано, что это специфическая задача с сильно несбалансированными классами
		ROC AUC не может учитывать все сразу, она показывает общее качество семейства классификаторов с разными порогами
		это все даже при использовании stratified k fold
2) (удивление) базовая модель дала ROC AUC 0.49-0.50 на 3 фолдах при кросс-валидации (то есть как рандомный ...)
	мысли:  см пункт 1
		стоит посмотреть разные метрики классификации, а так же стоит учитывать особенности аплифта -- нужны другие метрики
		нужно посмотреть не на ROC кривую, а на Lift кривую, разные пакеты (sklift ... от МТС), самому написать
3) (вопрос) какие модели стоит попробовать ?
	мысли:  тут был градиентый бустинг с 4000 деревьев, можно поиграться с их количеством и их глубиной, так как он может сильно
		переобучаться, можно попробовать не бустинг, а бэггинг (случайный лес)
		можно попробовать и более простые модели (линейные, просто для сравнения)
		можно строить ансамбли из разных моделей с учетом весов "правильности" моделей (блендинг)
4) (вопрос) что делать с признаками?
	мысли:  фильтровать, генерировать новые, снова фильтровать (feature importanse: PCA, RandmoForest.featur_importance_, ...)
		полиномиальные фичи для числовых признаков, SVM с полиномиальными ядрами
5) (вопрос) какие методы использования моделей пробовать ?
	мысли:  в статьях на хабре и обзорной (та, что на 30 стр) были описаны методы моделирования аплифта
		две модели, отдельно работающие на тех, кто отреагировал и нет
		одна модель, работающая с флагом воздействия на пользователя
		зависимые/независимые модели (было на хабре)




Процесс выполнения задания:
1) начал перечитывать туториал с хабра (пока только часть 1)
	X-learner (две зависимые модели) в [6] сп. лит. хабра часть 1 советуют применять при малой целевой группе
	общая идея : несбалансированная выборка по treat/control --> скоры от 1-й модели делаем фичами 2-й, у нее больше данных
2) пересмотрел доклад Ирины Елисовой (ссылка в 1 части туториала на хабре)
	там услышал что в статье Артема Бетлея ([5] из сп.лит. 1 части туториала) хорошо описаны метрики
		Uplift Prediction with Dependent Feature Representation in Imbalanced Treatment and Control Conditions
	посмотрел в сп.лит. части 1, увидел статью Radcliffe (2007), про нее видел, что в ней тоже неплохо описаны метрики
		Using Control Groups to Target on Predicted Lift: Building and Assessing Uplift Models
3) прочитал две статьи из прошлого пункта и статью только про метрики (с KDD 2018)
	статья Radcliffe (2007)
		Qini curve предложена как аналог ROC curve, но для изображения работы аплифт модели, для оценки аплифта
		чем она выше, тем лучше, все как у ROC кривой, просто формула отличается, ну и поведение мб разное у нее
		оптимальная Qini curve -- всех откликнувшихся в топ, далее не откликнувшиеся, но и не навредившие, затем навредившие
		навредившие / отказавшиеся сотрудничать -- негативные эффекты воздействия, которые хотелось бы избежать
		если нет негативных эффектов, то Qini curve идет сначала под 45 градусов (по оси Y # чел/, а не доля выборки),
			т.к. сначала все подверженные воздействию, затем нет откликов новых, поэтому аплифт выше не может быть, 
			а затем конец ... в этом случае
		а вот если есть негативные эффекты, то в конце не просто конец, а падение под 45 вних у Qini кривой, так как
			эти люди отказываются от сделки, то есть они в минус уводят инкрементальный эффект, поэтому конечная точка
			находится ниже максимума Qini curve
		если же построить Qini curve так, как будто не было негативных эффектов, то конечная точка у нее будет как и у прежней,
			учитывающей негативные эффекты, но только это точка будем на уровне максимума этой кривой, которая на максимуме
			равна константе, а до этого она тоже идет под 45, поэтому получим оптимальную "zero downlift curve", которая
			выглядит как обычная Qini без негативных эффектов, но заканчивающаяся в точке, которая является конечной для
			Qini curve, учитывающей эти негативные эффекты
		Q = (площадь м/у диагональю и кривой Qini нашей модели) / (площадь м/у диагональю и оптимальной кривой Qini)
		q0 = (площадь м/у диагональю и кривой Qini нашей модели) / (площадь м/у диагональю и "zero downlift curve" optim Qini)
		q0 может быть больше 100%

		ещё -- почему аплифт модели строят для хорошо продаваемых продуктов ?
			потому что если продукт продается не очень хорошо, то те, кто его мог бы купить, подд воздействием могут не купить
			поэтому лучше смотреть не аплифт, а просто вероятность покупки при коммуникации, то есть ... response modelling
			
		обычно причины у доп откликов из-за коммуникации и откликов, которые стандартны для задачи -- разные
			поэтому традиционные модели показывают себя хуже, чем аплифтовые, и иногда хуже случайного коммуницирования...
		вполне обычная картина : usual response rate 1%, after uplift modelling 1.1%
			это, и вычитание моделей со своими ошибками предсказания, может привести к большой ошибке итоговой модели ...
		также стоит обращать внимание на зашумленность данных -- эффект аплифта около 5-20% от обычного числа откликов
			поэтому от шума надо избавляться
	
	советы из Radcliffe(2007)
		variable selection
		binning methods
		bagging
		noise reduction
		stratified sampling
		cross validation
	
	статья Артема Бетлея ([5] из сп.лит. 1 части туториала)
		там предлагаются два пути решения проблемы несбалансированности целевой и контрольной групп
			DDR (Dependent Data Representation) -- предсказания одной модели становятся фичами другой, которая выучит аплифт
				как метод двух моделей с хабра, но только тут ко второй модели добавляем фичи
			SDR (SharedData Representation) -- есть признаки, есть индикатор целевой группы, делаем фичами их произведения
				можно отдельно регуляризовать веса изначальных фичей w_0 и веса признаков произведений индикатора и фичей w_1
		описаны разные уже существующие методы моделирования аплифт
			две независмые модели
			преобразование таргета (P_T(Y=1|X) - P_C(Y=1|X) = 2P(Z=1|X) - 1, X = YT + (1-Y)(1-T)) -- и дальше любой классификатор
				недостаток: Z=1 объединяет две разные группы с одним исходом, в случае дисбаланся T,C ... сложно
			есть ссылки на статьи об SVM (там нужны 2 гиперплоскости уже ...) и деревьях в аплифте
		также там рассказывается о метриках с единой точки зрения и том, как выбрать нужную метрику в конкретной задаче
			в случае дисбаланса Treatment, Control групп стоит использовать кривую Qini, она использует нормировку на размеры классов
			если со временем новые данные изменят баланс классов -- то метрика Qini сильно не потсрадает, она робастна к такому
		их эксперименты были на двух датасетах
			Hillstrom dataset == results of an e-mail campaign for an Internet based retailer
			CRITEO-UPLIFT1 == incrementality test, random part of the population not targeted by ads
			предобрабатывают, используют sklearn, делают 50 рандомных сплитов на трейн/тест с T/C как 70/30 (Treatment / Control)
			DDR, SDR -- для них делают регуляризацию отдельно на признаках и их произведениях с индикатором воздействия, подбор по сетке
			проверяют статистически значимое различие парным t-test 5%
			результаты работы метода DDR
				DDR -- улучшение two-model подхода, поэтому с ним и сравнивали, на Hillstrom dataset
				контроль брали 100%, 50%, 10% от изначального объема, имтировали несбалансированность Control Treatment
				DDR лучше two-model на несбалансированных T-C выборках в терминах метрики Q
				сравнили C->T схему обучения моделей (одну на Control, ее предсказания фичами для модели на Treatment) и T->C
					C->T показала себя лучше для несбалансированных выборок
					C->T -- uplift = P_T(Y|X,P_C(X)) - P_C(X)
				проверили на сложность взаимосвязь treatment и фичей -- можно ли предсказывать просто константу на группе T или C
					оказалось, что нельзя, есть некоторые взаимосвязи, причем если predict const для T, то результат ещё хуже
			результаты работы метода SDR
				сравнивали с методом трансформации таргета (Revert Label, формула выше была с Z = YT + (1-Y)(1-T))
				SDR куда лучше на несбалансированных выборках, на сбалансированной он тоже лучше, чем Revert Label
				провели эксперимент по оценке важности фичей, являющихся произведениями изначальных фичей и индикатора Treatment
				получилось, что они очень важны, без них качество модели заметно ниже
			в планах указали исследование сильно нелинейных зависимостей для поиска взаимосвязи между treatment индикатором и откликом
4) посмотрел два выступления Валерия Бабушкина по аплифту, там была ссылка на статью 2013 года (Гельман ... ?), где был предложен
   метод построения деревьев с заменой impurity (H(X) -- информационный критерий) на аплифт, который будет максимизироваться (разница
   между нодой и суммой ее двух потомков -> max), но есть реализация только на R, на Python нет, поэтому надо будет написать самому, но
   формулы есть в его слайдах
5) прочитал ноутбук на каггл (https://www.kaggle.com/code/davinwijaya/uplift-modeling-qini-curve-with-python/notebook)
   там посмотрел пример построения кривой Qini, анализа данных и работы с модельками, типы моделек  ("для ознакомления")
	довольно хорошо показывает как можно закодить метрики и как вывести графики кривых Qini
6) прочитал туториал на хабре часть 2, проявилось непонимание, как именно вычислять KL(P:Q) для разбиения ноды на два листа в аплифт дереве
   там смотрится KL(P_L^T, P_L^C) + KL(P_R^T, P_R^C) - KL(P^T, P^C) ... ? L-left, R-right, без нижнего индекса -- в текущей ноде
   при этом просто смотрят на доли откликнувшихся людей их контрольной и целевой групп, и хотят через KL получить максимальное расхождение 
   в этих долях по двум новым нодам относительно исходной ноды ... ? 
7) прочитал туториал на хабре часть 3 про метрики, вроде бы вопросов не возникло, подумал использовать уже их библиотеку, 
   но может только дерево написать свое, потренироваться, да и у них в моделях не увидел модели такой ... 
8) пересмотрел по диагонали с остановками на графиках, таблицах, формулах статью Radcliffe & Surry (2011) "Real world uplift modelling: significance-based uplift trees"
	significanse-based trees:  
		significanse-based критерий разбиения
			обычные деревья стремятся
				разница в outcomes для поддеревьев --> max
				разница в размераз для поддеревьев --> min
			предлагаемый критерий смотрит не на purchase rate или что-то похожее, а на общий аплифт
			критерий "delta delta p" (просто разница в аплифтах поддеревьев) тут не помог, но Hansotia & Rukstales (Incremental value modeling, 2001) помог
			критерий просто в виде Qini метрики ухудшил качество (возможно, т.к. показывает лишь качество ранжирования объектов)
			ad hoc критерий с uplift penalizing (delta / ((N_L + N_R) / 2min(N_L, N_R))^k), учитывающим размеры поддеревьев
				но подбрать оптимальное k у Radcliffe & Surry для реальных задач не получилось
			метод из статьи строит для каждого возможного сплита линейную модель и смотрит на важность interaction term как на критерий качества разбиения
				важность -- t-statistic (Jennings, Statistics 512: Applied linear models, topic 3, chapter 5. Technical report, Perdue University,2004)
				используют оценку для вычисления важности gamma_TR
		variance-based прунинг
			
		bagging
		pessimistic qini-based variable selection
9) пересмотрел доклад Максима Коматовского на митапе в августе, вроде все понял, но к некоторым вещам просто ещё нужно привыкнуть, некоторые понять или узнать
	(несколько контрольных групп, методы коммуникации, правила понижения и повышения ставок, взаимодействие с бизнесом)
10) замахнемся на статью про метрики с KDD 2018 ... ? Radcliffe, Surry


Словарик
 0) net effect -- чистый эффект
 1) attrition -- отсев, отток, выбывание ... attrition modelling -- моделирование оттока
 2) utility -- полезность
 3) former case -- предыдущий случай
 4) excess -- избыток, излишек, превышение
 5) invoke -- сослаться, вызвать (invoke negative effects -- "не учитывая/рассматривая/помня негативные эффекты" ... ? )
 6) problem was tackled -- ... решена 
 7) models diverge -- расходятся (devergence -- дивергенция, расхождение) 
 8) witness -- свидетель, очевидец
    witness smth. -- быть свидетелем
 9) The results are striking -- ... поразительные
10) to tackle -- бороться с, решать (проблему), "для решения (этой проблемы)"
11) to be doom to failure -- быть обреченным на провал, неудачу, поражение
12) substantial -- существенный
13) interaction, intervention -- взаимодействие, вмешательство
14) merits -- достоинства, заслуги, преимущества
15) in the former -- в прежнем, в первом (например, случае)
    in the latter -- в последнем (например, случае)
		it is studied in ... and ...
		in the FORMER (the first ...), it is ...
		in the LATTER (the second ...), it is ...
16) treatment is exposure to medicine -- лечение заключается в воздействии препаратов
    exposing users to ads -- демонстрация пользователям рекламы
17) enforce -- соблюдать
18) to inform further actions -- для обоснвания дальнейших действий
19) Our main contributions are threefold. -- Наш основной вклад состоит из трех частей.
20) a unified view -- единый взгляд
21) palpable evidence -- ощутимое (весомое) доказательство
22) to posit -- утверждать, позиционировать
23) drastically -- кардинально
24) conjunction -- связь, объединение
25) covariate -- независимая переменная (одно из значений)
26) proceed -- продолжить, перейти к
27) drawbacks -- недостатки
28) investigate -- изучить, исследовать
29) conversely -- напротив, наоборот
30) plausible -- правдоподобный
31) whereby -- посредством чего
32) 