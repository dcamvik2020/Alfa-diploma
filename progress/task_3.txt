Срок: до 25 ноября

Задание: попробовать написать код на базе полученных знаний для задачи с каггл
         https://www.kaggle.com/datasets/arashnic/uplift-modeling/code?select=criteo-uplift-v2.1.csv


Появившиеся вопросы:
1) Как меняется качество модели при разных делениях на train, val?
   в каггл задаче по оттоку клиентов от DLS ROC-AUC при train-val 
   (без двух наименее важных фичей из feature_importances_, 
   4 лучшие модели дали скоры и они стали фичами для финальной) :
     90/10 --> val roc_auc: 0.8091
 	 85/15 --> val roc_auc: 0.8264
 	 80/20 --> val roc_auc: 0.8329
	 75/25 --> val roc_auc: 0.8288
	 70/30 --> val roc_auc: 0.8386
2) Как в реальности выбирают соотношение данных на train-val-test ?
3) Как подбирать параметры моделей (например, у catboost)?
4) Как работать с данными где почти все признаки категориальные?
5) Есть ли какие-то наиболее хорошо показавшие в больших проектах методы 
   работы с несбалансированными классами?
6) Процесс генерации, отбора признаков, бинаризации числовых -- итерационный (строим модель и смотрим)?
   Или есть какие-то практики автоматизированные или оформленные в виде правил?

План:
- 6 ноутбуков с датасетом criteo
- прочитать статью про данные из ноутбука с каггл

Процесс выполнения:
1) написал первый вариант кода для аплифта 
   обзор данных и распределений признаков
   crosstab для тритмента, таргета
   модели (solo, two ddr/sdr) --> solo-model лучше всех оказался
   генерация фичей не получилась (пока не разобрался с выскакивающей ошибкой) 
		(но как генерировать и отбирать признаки, не зная их наименования/смысла)
2) порешал другую задачу с каггл от DLS(отток клиентов)
   посмотрел на ROC-AUC catboost в зависимости от числах лучших признаков для разных чисел деревьев, глубины, lr
   посмотрел на feature_importances_ catboost, обучал с разным количеством лучших признаков
   затем посмотрел ещё раз на данные -- только 2 числовых признака, которые можно бинаризовать ... это дало плоды
      дефолтный катбуст сразу на 1% больше auc_roc показал
	  получилось так, что все признаки только категориальные
3) подкинули ещё задачу с каггл на отток клиентов
   возникли две подзадачи (многоклассовой сильно несбалансированной классификации и регрессии) для предсказания дополнительных признаков
   изначально классы были несбалансированы по целевой переменной
   вспомнил про апсемпл минорного класса, про метрики регрессии и попробовал много комбинация гиперпараметров для catboost
   получилось заметить, какие гиперпараметры заходят лучше 
   отбирал признаки по качеству модели на топ k фичей в отсортированном по feature_importances_ (из catboost) порядке (строил графики)
   пару раз строил learning curve для моделей (качество в зависимости от размера обучающей выборки), но в итоге не сильно опирался на это
   

Замечания:
1) 
2) 
3) 
4) 