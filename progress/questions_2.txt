Вопросы
а) на проверку
б) без ответа
в) по технологиям, библиотекам, методам


На проверку
1) Оптимальная Qini кривая (на графиках обычно красным)
	недостижима на практике
	теоретический максимум аплифт модели
	всех убеждаемых ставит перед всеми, далее тех, кто не реагирует негативно на коммуникацию, в конце "negative effects" (тип "не беспокоить")
	поэтому ОПТИМАЛЬНАЯ кривая аплифта так и выглядит обычно
	сначала под 45 градусов (если шкалы в одном масштабе) (все убеждаемые в топе, рост 1 к 1 с долей протаргетированных клиентов)
	потом константа (всех откликнувшихся учли, но ещё не учли тип "не беспокоить", поэтому аплифт не меняется)
	а потом под 45 вниз, до уровня "overall uplift" (аплифта по всейй выборки, если провзаимодействовать со всеми)
2) Почему baseline (взаимодействие со случайными клиентами) имеет диагональный (или скорее линейный) вид на графике аплифта?
	выборку считаем довольно большой
	целевую и контрольные группы тоже
	поэтому считаем убеждаемые люди равномерно распределены по выборке, это как в однородном стержне, масса линейна, так как плотность постоянно
	тут коэффициентом наклона служит вероятность P(Y=1), которая для больших выборок примерно одинаковая
	не стоит забывать, то аплифт график показывает лишь оценку, поэтому эта диагональ показывает лишь самую простую модель
3) "zero downlift curve" -- это оптимальная кривая Qini, не учитывающая негативных эффектов, которая заканчивается в точке, в
	которой заканчивается оптимальная кривая Qini, учитывающая негативные эффекты ??
	тогда понятно, почему q0 может быть больше 100%
	мой ответ: судя по статье "quality measures for uplift modelling" именно так
4) почему идеальная uplift кривая в туториале часть 3 имеет форму колокола, а
   идеальная qini кривая в туториале часть 3 имеет горизонтальный участок
	мой ответ: из статьи про метрики аплифта с KDD --> Figure 10 (важны размеры treatment, control)
5) Как улучшают стабильность аплифт моделей на примере LQE (Low Qini Estimates)? 
   В статье Radcliffe & Surry (на 33 стр) был метод
   делают n~8 бутстрапированных выборок из сходной, на них считают оценки qini (по предсказаниям модели) q_1, ..., q_n
   и затем вычитают из оценки q ... s (sample standard deviation), умноженное на коэфф. от 0 до 1 (Чаще от 0.5 до 1) 
   его можно увеличить для большей стабильности, а можно уменьшить для большей предсказательной силы
   правильно ли я понял?


Без ответа
1) Что такое конверсия?
2) Что такое REST API? Нужно ли будет такое писать дата саентисту, стажеру?
3) Чем отличается exposure от visit & conversion связки (в сореве на каггл от Criteo)?
4) в чем отличие uplift & qini кривых из доклада Ирины Елисовой?
   когда лучше применять одну, когда применять другую, ведь они похожи по смыслу?
5) Как проводить отбор признаков и анализ датасета с помощью Net Information Value и Net Weight of Evidence


Технологии, библиотеки, методы:
1) Какие библиотеки часто используются в аплифте? 
   наиболее понятные, можно на дипломе будет посравнивать, но вообще от МТС хорошая (scikit-uplift), causalml похуже
2) Часто ли используются в работе библиотеки pycaret, mlextend, optuna? 
   редко, пока можно забить
3) Какой бустинг (XGBoost, LightGBM, CatBoost) показал себя лучше?
   по метрикам качества -- лидеры последние два
   по скорости сравнимы
   но обычно исопльзуют CatBoost
4) Что учить в ближайшие 3 месяца? Какие приоритеты от 1 до 5(высший)?
   Hadoop (весь стек, то есть с Hive и т.д.) 5
   Spark 3
   Ansible 2 (не везде применяется)
   Docker 5
   Kafka 4 (для онлайн моделей это основное, но их мало)
   mlflow 3
   airflow 3
   kubernetes 4
5) Какие методы анализа важности признаков стоит знать? SHAP values часто применяются на практике?
   как раз оба пункта -- основное, всегда эти числа в отчетах, для деревянных моделей точно
   и иногда корреляции разные смотрят (но это уже не оч популярно)